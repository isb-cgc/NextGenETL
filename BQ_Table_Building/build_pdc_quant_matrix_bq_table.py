"""

Copyright 2019, Institute for Systems Biology

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

"""
import os
import shutil

import requests

'''
Make sure the VM has BigQuery and Storage Read/Write permissions!
'''

import sys
from os.path import expanduser
import yaml
import io
from git import Repo
from json import loads as json_loads
from createSchemaP3 import build_schema
from common_etl.support import get_the_bq_manifest, confirm_google_vm, create_clean_target, \
                               generic_bq_harness, build_file_list, upload_to_bucket, csv_to_bq, \
                               build_pull_list_with_bq, BucketPuller, build_combined_schema, \
                               delete_table_bq_job, install_labels_and_desc, update_schema_with_dict, \
                               generate_table_detail_files, publish_table


'''
----------------------------------------------------------------------------------------------
The configuration reader. Parses the YAML configuration into dictionaries
'''
def load_config(yaml_config):
    yaml_dict = None
    config_stream = io.StringIO(yaml_config)
    try:
        yaml_dict = yaml.load(config_stream, Loader=yaml.FullLoader)
    except yaml.YAMLError as ex:
        print(ex)

    if yaml_dict is None:
        return None, None, None

    return yaml_dict['files_and_buckets_and_tables'], yaml_dict['steps']


'''
----------------------------------------------------------------------------------------------
Join quant matrix table and biospeciman table
'''

def join_quant_matrix_and_biospeciman_table(quant_matrix_table, biospeciman_table, target_dataset, joined_table, do_batch):
    sql = build_join_quant_matrix_and_biospeciman_table_sql(quant_matrix_table, biospeciman_table)
    return generic_bq_harness(sql, target_dataset, joined_table, do_batch, True)

def build_join_quant_matrix_and_biospeciman_table_sql(quant_matrix_table, biospeciman_table):
    return '''
      WITH a1 as (
          SELECT 
            A.*,
            B.study_name,
            B.aliquot_id,
            B.sample_id,
            B.pdc_case_id
          FROM `{0}` as A 
          JOIN `{1}` as B 
          ON ((B.aliquot_submitter_id = A.aliquot_submitter_id) AND (B.study_id = A.study_id)))
    SELECT * FROM a1
        '''.format(quant_matrix_table, biospeciman_table)


'''
-----------------------------------------------------------------------------------------------------------------------
Join with PDC_Genes_To_Protein_Mapping_File (received from Paul from PDC)
'''

def join_quant_matrix_and_pdc_genes_to_protein_table(quant_matrix_table, pdc_genes_to_protein_table, target_dataset, joined_table, do_batch):
    sql = build_join_quant_matrix_and_pdc_genes_to_protein_sql(quant_matrix_table, pdc_genes_to_protein_table)
    return generic_bq_harness(sql, target_dataset, joined_table, do_batch, True)

def build_join_quant_matrix_and_pdc_genes_to_protein_sql(quant_matrix_table, pdc_genes_to_protein_table):
    return '''
      WITH a1 as (
          SELECT 
            A.*,
            B.authority,
            B.ncbi_gene_id,
            b.gene_id,
            B.description,
            B.organism,
            B.chromosome,
            B.locus,
            B.proteins,
            B.assays,
            B.access,
            B.cud_label,
            B.updated
          FROM `{0}` as A 
          JOIN `{1}` as B 
          ON (B.gene_name = A.gene))
    SELECT * FROM a1
        '''.format(quant_matrix_table, pdc_genes_to_protein_table)


'''
-----------------------------------------------------------------------------------------------------------------------
Join with PDC_case_id_to_GDC_case_id mapping file (generated by build_pdc_aliquot_to_gdc_case.py)
'''
def join_quant_matrix_and_pdc_to_gdc_case_id_table(quant_matrix_table, pdc_to_gdc_case_id_table, target_dataset, joined_table, do_batch):
    sql = build_join_quant_matrix_and_pdc_to_gdc_case_id_table_sql(quant_matrix_table, pdc_to_gdc_case_id_table)
    return generic_bq_harness(sql, target_dataset, joined_table, do_batch, True)

def build_join_quant_matrix_and_pdc_to_gdc_case_id_table_sql(quant_matrix_table, pdc_to_gdc_case_id_table):
    return '''
      WITH a1 as (
          SELECT 
            A.*,
            B.gdc_id as gdc_case_id
          FROM `{0}` as A 
          JOIN `{1}` as B 
          ON (B.case_id = A.pdc_case_id))
    SELECT * FROM a1
        '''.format(quant_matrix_table, pdc_to_gdc_case_id_table)


def get_quant_matrix_table_one_study(pdc_api_end_point, study_id, study_submitter_id):
    quant_log2_ratio_query = ('{ quantDataMatrix(study_submitter_id: \"'
                              + study_submitter_id + '\" data_type: \"log2_ratio\") }')

    quant_res = requests.post(pdc_api_end_point, json={'query': quant_log2_ratio_query})

    if not quant_res.ok:
        print('Error: PDC API request did not return OK')
        return None

    json_res = quant_res.json()

    if 'errors' in json_res:
        print('No quant matrix for study_submitter_id = ' + study_submitter_id)
        return None

    print('Got quant matrix for study_submitter_id = ' + study_submitter_id)
    quant_matrix = json_res[u'data'][u'quantDataMatrix']

    first_row_data = quant_matrix[0]
    for i in range(1, len(first_row_data)):
        if ":" in first_row_data[i]:
            aliquot_submitter_id = first_row_data[i].split(":")[1]
        else:
            print('no : in here ' + first_row_data[i])
            aliquot_submitter_id = first_row_data[i]
        quant_matrix[0][i] = aliquot_submitter_id

    print('Converted first row to aliquot_submitter_id')

    num_rows = len(quant_matrix)
    num_cols = len(quant_matrix[0])
    quant_matrix_table = []
    quant_matrix_table.append(['study_id', 'aliquot_submitter_id', 'gene', 'log2_ratio'])
    for i in range(1, num_rows):
        for j in range(1, num_cols):
            log2_value = quant_matrix[i][j]
            gene = quant_matrix[i][0]
            aliquot_submitter_id = quant_matrix[0][j]
            quant_matrix_table.append([study_id, aliquot_submitter_id, gene, log2_value])

    print('Converted quant matrix into rows of log2ratio values')
    return quant_matrix_table


def write_quant_matrix_table_to_tsv(quant_matrix_table, tsv_file):
    with open(tsv_file, "w") as tsv_out:
        num_rows = len(quant_matrix_table)
        for i in range(0, num_rows):
            tsv_out.write("\t".join([quant_matrix_table[i][0],
                                    quant_matrix_table[i][1],
                                    quant_matrix_table[i][2],
                                     quant_matrix_table[i][3]]) + "\n")
    return True


def get_biospeciman_table_one_study(pdc_api_end_point, study_id):
    print('Getting biospeciman table for study ' + study_id)
    biospeciman_query = '{ biospecimenPerStudy(study_id: "' + \
            study_id + '"' + \
            ') { aliquot_id sample_id case_id aliquot_submitter_id sample_submitter_id case_submitter_id aliquot_status' \
            ' case_status sample_status project_name sample_type disease_type primary_site pool taxon} }'

    biospeciman_res = requests.post(pdc_api_end_point, json={'query': biospeciman_query})

    if not biospeciman_res.ok:
        print('Error: PDC API request did not return OK')
        return None

    json_res = biospeciman_res.json()

    if 'errors' in json_res:
        print('No biospeciman table for study_id = ' + study_id)
        return None

    print('Got biospeciman table for study_id = ' + study_id)
    biospeciman = json_res[u'data'][u'biospecimenPerStudy']

    print('Getting study info for study ' + study_id)
    study_info_query = '{ study(study_id: "' + \
                study_id + '"' + \
                ') { study_id pdc_study_id study_submitter_id study_name} }'

    study_info_res = requests.post(pdc_api_end_point, json={'query': study_info_query})

    if not study_info_res.ok:
        print('Error: PDC API request did not return OK')
        return None

    json_res = study_info_res.json()
    study_info = json_res[u'data'][u'study']
    study_name = study_info[0][u'study_name']

    print('Generating biospeciman table')
    num_rows = len(biospeciman)
    table = []
    table.append(['study_id', 'aliquot_submitter_id', 'study_name', 'aliquot_id', 'sample_id', 'pdc_case_id'])
    for i in range(0, num_rows):
        aliquot_id = biospeciman[i][u'aliquot_id']
        sample_id = biospeciman[i][u'sample_id']
        aliquot_submitter_id = biospeciman[i][u'aliquot_submitter_id']
        pdc_case_id = biospeciman[i][u'case_id']
        table.append([study_id, aliquot_submitter_id, study_name, aliquot_id, sample_id, pdc_case_id])

    return table


def write_biospeciman_table_to_tsv(biospeciman_table, tsv_file):
    with open(tsv_file, "w") as tsv_out:
        num_rows = len(biospeciman_table)
        for i in range(0, num_rows):
            tsv_out.write("\t".join([biospeciman_table[i][0],
                                    biospeciman_table[i][1],
                                    biospeciman_table[i][2],
                                    biospeciman_table[i][3],
                                    biospeciman_table[i][4],
                                    biospeciman_table[i][5]]) + "\n")
    return True


def create_clean_target(local_files_dir):
    """
    GDC download client builds a tree of files in directories. This routine clears the tree out if it exists.
    """

    if os.path.exists(local_files_dir):
        print("deleting {}".format(local_files_dir))
        try:
            shutil.rmtree(local_files_dir)
        except OSError as e:
            print("Error: %s - %s." % (e.filename, e.strerror))

        print("done {}".format(local_files_dir))

    if not os.path.exists(local_files_dir):
        os.makedirs(local_files_dir)


'''
----------------------------------------------------------------------------------------------
Pipeline for all studies
'''

def generate_quant_matrix_bq_table_all_studies(params):
    pdc_end_point = params['PDC_API_END_POINT']

    home = expanduser("~")
    quant_matrix_tsv = "{}/{}".format(home, params['QUANT_MATRIX_TSV'])
    biospeciman_tsv = "{}/{}".format(home, params['BIOSPECIMAN_TSV'])

    hold_schema_dict_quant_matrix = "{}/{}".format(home, params['HOLD_SCHEMA_DICT_QUANT_MATRIX'])
    hold_schema_list_quant_matrix = "{}/{}".format(home, params['HOLD_SCHEMA_LIST_QUANT_MATRIX'])
    hold_schema_dict_biospeciman = "{}/{}".format(home, params['HOLD_SCHEMA_DICT_BIOSPECIMAN'])
    hold_schema_list_biospeciman = "{}/{}".format(home, params['HOLD_SCHEMA_LIST_BIOSPECIMAN'])

    studies = pull_all_studies(pdc_end_point)
    for study in studies:
        study_submitter_id = study['study_submitter_id']
        study_id = study['study_id']
        print("** Study ID = {}, Study submitter ID = {} **".format(study_id, study_submitter_id))
        print("Step 1: get_quant_matrix_table_one_study")
        quant_matrix_table = get_quant_matrix_table_one_study(pdc_end_point, study_id, study_submitter_id)

        # Some study does not have quant_matrix
        if quant_matrix_table:
            bq_table_name_quant_matrix = "PDC_Quant_Matrix_{}".format(study_submitter_id)
            bq_table_name_biospeciman = "PDC_Biospeciman_{}".format(study_submitter_id)
            bq_table_name_joined_quant_matrix_biospeciman = "PDC_Joined_QM_Bio_{}".format(study_submitter_id)
            bq_table_name_joined_pdc_gene_map = "PDC_Joined_QM_Bio_Gene_Map_{}".format(study_submitter_id)
            bq_table_name_final_table = "PDC_Final_Table_{}".format(study_submitter_id)

            print("Step 2: write_quant_matrix_table_to_tsv")
            write_quant_matrix_table_to_tsv(quant_matrix_table, quant_matrix_tsv)

            bucket_quant_matrix = '{}/{}'.format(params['WORKING_BUCKET_DIR'], params['BUCKET_TSV_QUANT_MATRIX'])

            print("Step 3: upload_quant_matrix_tsv_to_bucket")
            upload_to_bucket(params['WORKING_BUCKET'], bucket_quant_matrix, quant_matrix_tsv)

            print("Step 4: create_quant_matrix_bq_from_tsv")
            typing_tups = build_schema(quant_matrix_tsv, params['SCHEMA_SAMPLE_SKIPS'])
            build_combined_schema(None, None,
                                  typing_tups, hold_schema_list_quant_matrix, hold_schema_dict_quant_matrix)
            bucket_src_url = 'gs://{}/{}'.format(params['WORKING_BUCKET'], bucket_quant_matrix)
            with open(hold_schema_list_quant_matrix, mode='r') as schema_hold_dict:
                typed_schema = json_loads(schema_hold_dict.read())
            csv_to_bq(typed_schema, bucket_src_url, params['TARGET_DATASET'], bq_table_name_quant_matrix,
                      params['BQ_AS_BATCH'])

            print("Step 5: get_biospeciman_table_one_study")
            biospeciman_table = get_biospeciman_table_one_study(params['PDC_API_END_POINT'],
                                                                study_id)

            print("Step 6: write_biospeciman_table_to_tsv")
            write_biospeciman_table_to_tsv(biospeciman_table, biospeciman_tsv)

            print("Step 7: upload_biospeciman_tsv_to_bucket")
            upload_to_bucket(params['WORKING_BUCKET'], bucket_quant_matrix, biospeciman_tsv)

            print("Step 8: create_biospeciman_bq_from_tsv")
            typing_tups = build_schema(biospeciman_tsv, params['SCHEMA_SAMPLE_SKIPS'])
            build_combined_schema(None, None,
                                  typing_tups, hold_schema_list_biospeciman, hold_schema_dict_biospeciman)
            bucket_src_url = 'gs://{}/{}'.format(params['WORKING_BUCKET'], bucket_quant_matrix)
            with open(hold_schema_list_biospeciman, mode='r') as schema_hold_dict:
                typed_schema = json_loads(schema_hold_dict.read())
            csv_to_bq(typed_schema, bucket_src_url, params['TARGET_DATASET'], bq_table_name_biospeciman,
                      params['BQ_AS_BATCH'])

            print("Step 9: join_quant_matrix_and_biospeciman_table")
            quant_matrix_bq_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
                                                      params['TARGET_DATASET'],
                                                      bq_table_name_quant_matrix)
            biospeciman_bq_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
                                                     params['TARGET_DATASET'],
                                                     bq_table_name_biospeciman)
            join_quant_matrix_and_biospeciman_table(quant_matrix_bq_table,
                                                    biospeciman_bq_table,
                                                    params['TARGET_DATASET'],
                                                    bq_table_name_joined_quant_matrix_biospeciman,
                                                    params['BQ_AS_BATCH'])

            print("Step 10: join_quant_matrix_and_pdc_genes_to_protein_table")
            quant_matrix_biospeciman_bq_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
                                                                  params['TARGET_DATASET'],
                                                                  bq_table_name_joined_quant_matrix_biospeciman)
            pdc_genes_protein_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
                                                        params['TARGET_DATASET'],
                                                        params['TARGET_TABLE_PDC_GENES_PROTEIN'])
            join_quant_matrix_and_pdc_genes_to_protein_table(quant_matrix_biospeciman_bq_table,
                                                             pdc_genes_protein_table,
                                                             params['TARGET_DATASET'],
                                                             bq_table_name_joined_pdc_gene_map,
                                                             params['BQ_AS_BATCH'])

            # TODO: This step not successful for one study test, join with pdc_to_gdc_case_id do not have case_id match
            # print("Step 11: join_quant_matrix_and_pdc_to_gdc_case_id_table")
            # quant_matrix_and_pdc_genes_to_protein_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
            #                                                                 params['TARGET_DATASET'],
            #                                                                 bq_table_name_joined_pdc_gene_map)
            # pdc_to_gdc_case_id_table = "{}.{}".format(params['WORKING_PROJECT'],
            #                                           params['PDC_TO_GDC_CASE_ID_MAPPING_TABLE'])
            # join_quant_matrix_and_pdc_to_gdc_case_id_table(quant_matrix_and_pdc_genes_to_protein_table,
            #                                                pdc_to_gdc_case_id_table,
            #                                                params['TARGET_DATASET'],
            #                                                bq_table_name_final_table,
            #                                                params['BQ_AS_BATCH'])

            print("--- Finished process Study ID = {}, Study submitter ID = {}---".format(study_id, study_submitter_id))


def pull_all_studies(pdc_end_point):
    all_progs_query = """{allPrograms{
            program_id
            program_submitter_id
            name
            projects {
                project_id
                project_submitter_id
                name
                studies {
                    study_id
                    submitter_id_name
                    study_submitter_id
                    analytical_fraction
                    experiment_type
                    acquisition_type
                }
            }
        }}"""

    response = requests.post(pdc_end_point, json={'query': all_progs_query})

    studies = []

    if response.ok:
        json_res = response.json()
        for program in json_res['data']['allPrograms']:
            for project in program['projects']:
                for study in project['studies']:
                    study_dict = study.copy()
                    study_dict['program_id'] = program['program_id']
                    study_dict['program_submitter_id'] = program['program_submitter_id']
                    study_dict['program_name'] = program['name']
                    study_dict['project_id'] = project['project_id']
                    study_dict['project_submitter_id'] = project['project_submitter_id']
                    study_dict['project_name'] = project['name']
                    studies.append(study_dict)
    else:
        response.raise_for_status()

    return studies


'''
----------------------------------------------------------------------------------------------
Main Control Flow
Note that the actual steps run are configured in the YAML input! This allows you
to e.g. skip previously run steps.
'''
def main(args):

    if not confirm_google_vm():
        print('This job needs to run on a Google Cloud Compute Engine to avoid storage egress charges [EXITING]')
        return

    if len(args) != 2:
        print(" ")
        print(" Usage : {} <configuration_yaml>".format(args[0]))
        return

    print('job started')

    #
    # Get the YAML config loaded:
    #

    with open(args[1], mode='r') as yaml_file:
        params, steps = load_config(yaml_file.read())

    #
    # Schemas and table descriptions are maintained in the github repo:
    #
    home = expanduser("~")
    local_files_dir = "{}/{}".format(home, params['LOCAL_FILES_DIR'])
    quant_matrix_tsv = "{}/{}".format(home, params['QUANT_MATRIX_TSV'])
    biospeciman_tsv = "{}/{}".format(home, params['BIOSPECIMAN_TSV'])

    hold_schema_dict_quant_matrix = "{}/{}".format(home, params['HOLD_SCHEMA_DICT_QUANT_MATRIX'])
    hold_schema_list_quant_matrix = "{}/{}".format(home, params['HOLD_SCHEMA_LIST_QUANT_MATRIX'])
    hold_schema_dict_biospeciman = "{}/{}".format(home, params['HOLD_SCHEMA_DICT_BIOSPECIMAN'])
    hold_schema_list_biospeciman = "{}/{}".format(home, params['HOLD_SCHEMA_LIST_BIOSPECIMAN'])

    if 'clear_target_directory' in steps:
        print('clear_target_directory')
        create_clean_target(local_files_dir)

    if 'generate_quant_matrix_bq_table_all_studies' in steps:
        # Do all studies...
        print('generate_quant_matrix_bq_table_all_studies')
        generate_quant_matrix_bq_table_all_studies(params)

    else:
        # Do one hard coded study to test...
        # Quant matrix table...
        if 'get_quant_matrix_table_one_study' in steps:
            print('get_quant_matrix_table_one_study')
            try:
                quant_matrix_table = get_quant_matrix_table_one_study(params['PDC_API_END_POINT'],
                                                                      params['ONE_STUDY_ID'],
                                                                      params['ONE_STUDY_SUBMITTER_ID'])
            except Exception as ex:
                print("get_quant_matrix_table_one_study failed: {}".format(str(ex)))
                return

        if 'write_quant_matrix_table_to_tsv' in steps:
            print('write_quant_matrix_table_to_tsv')
            success = write_quant_matrix_table_to_tsv(quant_matrix_table, quant_matrix_tsv)
            if not success:
                print("Failure writing quant matrix table to tsv")
                return

        bucket_quant_matrix = '{}/{}'.format(params['WORKING_BUCKET_DIR'], params['BUCKET_TSV_QUANT_MATRIX'])

        if 'upload_quant_matrix_tsv_to_bucket' in steps:
            print('upload_quant_matrix_tsv_to_bucket')
            upload_to_bucket(params['WORKING_BUCKET'], bucket_quant_matrix, quant_matrix_tsv)

        if 'create_quant_matrix_bq_from_tsv' in steps:
            print('create_quant_matrix_bq_from_tsv')
            typing_tups = build_schema(quant_matrix_tsv, params['SCHEMA_SAMPLE_SKIPS'])
            build_combined_schema(None, None,
                                  typing_tups, hold_schema_list_quant_matrix, hold_schema_dict_quant_matrix)
            bucket_src_url = 'gs://{}/{}'.format(params['WORKING_BUCKET'], bucket_quant_matrix)
            with open(hold_schema_list_quant_matrix, mode='r') as schema_hold_dict:
                typed_schema = json_loads(schema_hold_dict.read())
            csv_to_bq(typed_schema, bucket_src_url, params['TARGET_DATASET'], params['TARGET_TABLE_QUANT_MATRIX'], params['BQ_AS_BATCH'])


        # Biospeciman table...
        if 'get_biospeciman_table_one_study' in steps:
            print('get_biospeciman_table_one_study')
            try:
                biospeciman_table = get_biospeciman_table_one_study(params['PDC_API_END_POINT'],
                                                                    params['ONE_STUDY_ID'])
            except Exception as ex:
                print("get_biospeciman_table_one_study failed: {}".format(str(ex)))
                return

        if 'write_biospeciman_table_to_tsv' in steps:
            print('write_biospeciman_table_to_tsv')
            success = write_biospeciman_table_to_tsv(biospeciman_table, biospeciman_tsv)
            if not success:
                print("Failure writing biospeciman table to tsv")
                return

        if 'upload_biospeciman_tsv_to_bucket' in steps:
            print('upload_biospeciman_tsv_to_bucket')
            upload_to_bucket(params['WORKING_BUCKET'], bucket_quant_matrix, biospeciman_tsv)

        if 'create_biospeciman_bq_from_tsv' in steps:
            print('create_biospeciman_bq_from_tsv')
            typing_tups = build_schema(biospeciman_tsv, params['SCHEMA_SAMPLE_SKIPS'])
            build_combined_schema(None, None,
                                  typing_tups, hold_schema_list_biospeciman, hold_schema_dict_biospeciman)
            bucket_src_url = 'gs://{}/{}'.format(params['WORKING_BUCKET'], bucket_quant_matrix)
            with open(hold_schema_list_biospeciman, mode='r') as schema_hold_dict:
                typed_schema = json_loads(schema_hold_dict.read())
            csv_to_bq(typed_schema, bucket_src_url, params['TARGET_DATASET'], params['TARGET_TABLE_BIOSPECIMAN'], params['BQ_AS_BATCH'])


        # Join quant matrix table and biospeciman table...
        if 'join_quant_matrix_and_biospeciman_table' in steps:
            print('join_quant_matrix_and_biospeciman_table')
            quant_matrix_bq_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
                                                      params['TARGET_DATASET'],
                                                      params['TARGET_TABLE_QUANT_MATRIX'])
            biospeciman_bq_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
                                                      params['TARGET_DATASET'],
                                                      params['TARGET_TABLE_BIOSPECIMAN'])
            join_quant_matrix_and_biospeciman_table(quant_matrix_bq_table,
                                                    biospeciman_bq_table,
                                                    params['TARGET_DATASET'],
                                                    params['JOINED_QUANT_MATRIX_BIOSPECIMAN_TABLE'],
                                                    params['BQ_AS_BATCH'])


        # Join PDC_Quant_Matrix_Biospeciman_Joined_Table_One_Study and PDC_Genes_To_Protein_Mapping_File
        if 'join_quant_matrix_and_pdc_genes_to_protein_table' in steps:
            print('join_quant_matrix_and_pdc_genes_to_protein_table')
            quant_matrix_biospeciman_bq_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
                                                      params['TARGET_DATASET'],
                                                      params['JOINED_QUANT_MATRIX_BIOSPECIMAN_TABLE'])
            pdc_genes_protein_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
                                                      params['TARGET_DATASET'],
                                                      params['TARGET_TABLE_PDC_GENES_PROTEIN'])
            join_quant_matrix_and_pdc_genes_to_protein_table(quant_matrix_biospeciman_bq_table,
                                                    pdc_genes_protein_table,
                                                    params['TARGET_DATASET'],
                                                    params['JOINED_QUANT_MATRIX_BIOSPECIMAN_PDC_GENE_PROTEIN_TABLE'],
                                                    params['BQ_AS_BATCH'])

        # Join with PDC_to_GDC_case_id mapping file
        if 'join_quant_matrix_and_pdc_to_gdc_case_id_table' in steps:
            print('join_quant_matrix_and_pdc_to_gdc_case_id_table')
            quant_matrix_and_pdc_genes_to_protein_table = "{}.{}.{}".format(params['WORKING_PROJECT'],
                                                      params['TARGET_DATASET'],
                                                      params['JOINED_QUANT_MATRIX_BIOSPECIMAN_PDC_GENE_PROTEIN_TABLE'])
            pdc_to_gdc_case_id_table = "{}.{}".format(params['WORKING_PROJECT'],
                                                      params['PDC_TO_GDC_CASE_ID_MAPPING_TABLE'])
            join_quant_matrix_and_pdc_to_gdc_case_id_table(quant_matrix_and_pdc_genes_to_protein_table,
                                                    pdc_to_gdc_case_id_table,
                                                    params['TARGET_DATASET'],
                                                    params['FINAL_TABLE_ONE_STUDY'],
                                                    params['BQ_AS_BATCH'])

    print('job completed')


if __name__ == "__main__":
    main(sys.argv)
