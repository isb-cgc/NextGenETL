#
# YAML Configuration file used for script create_bq_datasets.py
# Create BQ datasets
#

version: 1
files_and_buckets_and_tables:

  # Where do we dump the schema git repository?
  SCHEMA_REPO_LOCAL: /full/path/to/local/schema_git_repo

  # Where is the repo?
  SCHEMA_REPO_URL: https://github.com/your_schema_repo.git

  # What repo directory holds the schema data files?
  RAW_SCHEMA_DIR: path_from_repo_top

  # What repo branch to use?
  SCHEMA_REPO_BRANCH: master

  # What file prefix hold the processed description (this is a prefix)
  PROX_DESC_PREFIX: /full/path/to/myProcessedDataDir

  # What project do we create the datasets in:
  TARGET_PROJECT: your_target_project_id

  # are the datasets to be made public (all authenticated users)?
  MAKE_ALL_PUBLIC: False

  # For each dataset to create, what is the json file in the repo:
  CREATE_LIST:
    - Your_dataset_1 : dataset_info_file.json
    - Your_dataset_2 : dataset_info_file_too.json

# Note that although the steps are given in the actual order here as
# a list, changing the order here does not change the order of execution, which is fixed.

steps:

  # Get the dataset description info pulled from git:
  - pull_dataset_info_from_git

  # Extract the description from each file:
  - process_git_schema

  # Create the dataset:
  - create_dataset