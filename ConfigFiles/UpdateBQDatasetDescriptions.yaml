#
# YAML Configuration file used for script install_bq_dataset_descriptions.py
# Update BQ dataset descriptions
#

version: 1
files_and_buckets_and_tables:

  # Where do we dump the schema git repository?
  SCHEMA_REPO_LOCAL: /full/path/to/local/schema_git_repo

  # Where is the repo?
  SCHEMA_REPO_URL: https://github.com/your_schema_repo.git

  # What repo directory holds the schema data files?
  RAW_SCHEMA_DIR: path_from_repo_top

  # What repo branch to use?
  SCHEMA_REPO_BRANCH: master

  # What file prefix hold the processed description (this is a prefix)
  PROX_DESC_PREFIX: /full/path/to/myProcessedDataDir

  # What project is the table in:
  TARGET_PROJECT: your_target_project_id

  # For each dataset to update, what is the json file in the repo:
  FIX_LIST:
    - Your_dataset_1 : dataset_info_file.json
    - Your_dataset_2 : dataset_info_file_too.json

# Note that although the steps are given in the actual order here as
# a list, changing the order here does not change the order of execution, which is fixed.

steps:

  # Get the dataset description info pulled from git:
  - pull_dataset_info_from_git

  # Extract the description from each file:
  - process_git_schemas

  # Update the dataset descriptions:
  - update_dataset_descriptions