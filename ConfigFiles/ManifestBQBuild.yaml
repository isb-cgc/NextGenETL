#
# YAML Configuration file used for script build_dcf_manfest_bq_tables.py
# Builds BQ tables for legacy and active DCF manifests, then creates pared-down
# UUID to gs URL mapping BQ tables.
#

version: 1
files_and_buckets_and_tables:
  # Run all BQ jobs in Batch mode? Slower but uses less of quotas:
  BQ_AS_BATCH: False

  # Where do we dump the schema git repository?
  SCHEMA_REPO_LOCAL: /full/path/to/local/schema_git_repo

  # Where is the repo?
  SCHEMA_REPO_URL: https://github.com/your_schema_repo.git

  # What file hold the schema data?
  RAW_SCHEMA_JSON: path_from_repo_top/table_info_file.json

  # What file prefix hold the processed schema and other descriptions (this is a prefix)
  PROX_DESC_PREFIX: /full/path/to/myManifestDesc

  # What bucket holds the tsv files that we need to import from the data node?
  SOURCE_BUCKET: data_node_source_bucket_name

  # What bucket holds the tsv files we will use to build the BQ tables?
  WORKING_BUCKET: your_working_bucket_name

  # The tsv files:
  ACTIVE_MANIFEST_TSV: Your_Active_Manifest_For_Release.tsv
  LEGACY_MANIFEST_TSV: Your_Legacy_Manifest_For_Release.tsv

  # What project are we in:
  WORKING_PROJECT: your_working_project_name

  # Where is the BQ table dataset:
  TARGET_DATASET: your_bq_dataset_name_in_working_project

  # BQ tables for file maps:

  ACTIVE_FILE_MAP_BQ: Your_Active_File_Map_Table_For_Release
  LEGACY_FILE_MAP_BQ: Your_Legacy_File_Map_Table_For_Release

  # BQ tables for manifest:

  ACTIVE_MANIFEST_BQ: Your_Active_Manifest_Table_For_Release
  LEGACY_MANIFEST_BQ: Your_Legacy_Manifest_Table_For_Release

  # Which tables do we build?

  DO_ACTIVE: True
  DO_LEGACY: True

  # What goes out for public consumption:

  COMBINED_TABLE: Your_pre_publication_table

  # Publication table:

  PUBLICATION_PROJECT: Your-publication-project
  PUBLICATION_DATASET: Your_publication_dataset
  PUBLICATION_TABLE: Your_publication_table

# Note that although the steps are given in the actual order here as
# a list, changing the order here does not change the order of execution, which is fixed.

steps:

  # Get the manifest from the source data node:
  - pull_manifest_from_data_node

  # Get the table schema/description/tags pulled from git:
  - pull_table_info_from_git

  # Extract the table schema/description/tags from that file:
  - process_git_schemas

  # Build the manifest tables from the imported tsvs:
  - create_bq_manifest_from_tsv

  # Build the file map bq tables from the manifest:
  - create_file_map_bq

  # Create a combined table for publication:
  - create_combined_table

  # install field descriptions:
  - add_combined_desc

  # Add table description and tags to combined table:
  - add_table_description

  # Publish the table:
  - publish