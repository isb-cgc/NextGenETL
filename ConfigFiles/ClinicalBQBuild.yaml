#
# YAML Configuration file used for script build_gdc_api_clinical_bulk_table.py
# Builds BQ table for clinical data.
#

version: 3

api_params:
  # GDC API endpoint for retrieval of cases dataset
  ENDPOINT: https://api.gdc.cancer.gov/cases

  # in case we switch back to relXX from rXX
  REL_PREFIX: 'r'

  # most recent GDC release number
  # (NOTE: pulls data from the current release regardless of value here, not currently
  # possible to specify a release number when making API calls.)
  RELEASE: '29'

  # How many case records to retrieve per GDC API call. Larger batch sizes are more
  # likely to fail before completion, seems to work consistently at 2500
  BATCH_SIZE: 1000

  # Start index for retrieving case records
  START_INDEX: 0

  # List of 'expand' field groups to include in the clinical data bq table
  # PARENT_FG: cases
  EXPAND_FG_LIST:
    - project
    - demographic
    - diagnoses
    - diagnoses.treatments
    - diagnoses.annotations
    - exposures
    - family_histories
    - follow_ups
    - follow_ups.molecular_tests

  # fields to exclude from the api call
  EXCLUDE_FIELDS:
    - aliquot_ids
    - analyte_ids
    - case_autocomplete
    - diagnosis_ids
    - id
    - portion_ids
    - sample_ids
    - slide_ids
    - submitter_aliquot_ids
    - submitter_analyte_ids
    - submitter_diagnosis_ids
    - submitter_portion_ids
    - submitter_sample_ids
    - submitter_slide_ids
    - project.primary_site
    - project.disease_type
    - project.released
    - project.state
    - project.releasable
    - project.intended_release_date
    - project.dbgap_accession_number

bq_params:
  ##
  #  File Locations, GDC Release, Naming Conventions
  ##

  # whether to load rows via batch (I've always used false)
  DO_BATCH: FALSE

  # Directory to which to write the cases clinical data json file
  SCRATCH_DIR: <your-scratch-dir>

  # What bucket is going to get the text file heading to BQ?
  WORKING_BUCKET: <your-working-bucket>

  # What is the file path to the text file in the bucket:
  WORKING_BUCKET_DIR: <your-bucket-directory>

  # name for master table (will be prefixed with GDC_RELEASE value)
  MASTER_TABLE: clinical

  LOCATION: US

  ##
  #  BigQuery API
  ##

  # What project are we in:
  DEV_PROJECT: <your-dev-project>

  # Where is the BQ table dataset:
  DEV_DATASET: <your-dev-dataset>

steps:
  # Note that although the steps are given in the actual order here as
  # a list, changing the order here does not change the order of execution, which is fixed.

  # - build_and_upload_case_jsonl

  # - create_schema

  # - build_bq_table