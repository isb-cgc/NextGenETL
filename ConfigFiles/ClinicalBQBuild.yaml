#
# YAML Configuration file used for script build_clinical_data_bq_table.py
# Builds BQ table for clinical data.
#

version: 1

params:
  # GDC API endpoint for retrieval of cases dataset
  ENDPOINT: 'https://api.gdc.cancer.gov/cases'

  # List of 'expand' field groups to include in the clinical data bq table
  EXPAND_FIELD_GROUPS: 'demographic,diagnoses,diagnoses.treatments,diagnoses.annotations,exposures,family_histories'

  # How many case records to retrieve per GDC API call.
  # Larger batch sizes are more likely to fail before completion, recommend leaving this set to 1000.
  BATCH_SIZE: 1000

  # Start index for retrieving case records
  START_INDEX: 0

  # Number of pages to write into json file (0 == all pages after start index)
  MAX_PAGES: 0

  # 'a' if appending to existing cases json (for continuation of interrupted file build).
  # 'w' if creating or overwriting existing CASES_JSON_FILE.
  IO_MODE: 'w'

  # File to which to write the cases clinical data json file
  OUTPUT_FILEPATH: '~/scratch/clinical_data.json'

  # Run all BQ jobs in Batch mode? Slower but uses less of quotas:
  BQ_AS_BATCH: False

  BQ_SCHEMA_FILEPATH: '~/schemaRepo/clinical_schema.json'


# Note that although the steps are given in the actual order here as
# a list, changing the order here does not change the order of execution, which is fixed.

steps:

  # Get the manifest from the source data node:
  - retrieve_and_output_cases

  # Get the table schema/description/tags pulled from git:
  - create_bq_schema_file
