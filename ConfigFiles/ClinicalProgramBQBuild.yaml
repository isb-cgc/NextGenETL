#
# YAML Configuration file used for script build_clinical_data_program_tables.py
# Builds Program BQ tables for clinical data.
#

version: 3

api_params:
  # GDC API endpoint for retrieval of cases dataset
  # ENDPOINT: 'https://api.gdc.cancer.gov/cases'
  ENDPOINT: URL/OF/API/ENDPOINT

  TABLE_METADATA:
    cases: # GDC expand field group name
      prefix: # desired table_abbreviation (e.g. demo)--leave blank for cases
      table_id_key: case_id # table's unique_id_key
      excluded_fields: # list of fields to exclude from bq table
        - submitter_id
      column_order:
        - biospecimen_type # list of field group's fields in desired bq table order

  # Determines table-level ordering, dictating ordering for merged tables
  TABLE_ORDER:
    - cases
    # ...
    - cases.follow_ups.molecular_tests

  # Directory for VM scratch files
  SCRATCH_DIR: local/directory/path

  # most recent GDC release number
  GDC_RELEASE: relXX

bq_params:
  # What project are we in:
  WORKING_PROJECT: your_working_project_id

  # Where is the BQ table dataset:
  TARGET_DATASET: your_bq_dataset_name_in_working_project

  # Metadata reference dataset
  METADATA_DATASET: GDC_metadata

  # What bucket is going to get the text file heading to BQ?
  WORKING_BUCKET: your_bucket_name

  # What is the file path to the text file in the bucket:
  WORKING_BUCKET_DIR: full/path/in/bucket # NO LEADING '/'

  # name for master table (will be prefixed with GDC_RELEASE value)
  MASTER_TABLE: clinical_data

  # Component of table name, differentiates that this is a clinical data table
  # base program table name form: GDC_RELEASE + '_' + TABLE_PREFIX  + '_' + program_name
  TABLE_PREFIX: clin

# Note that although the steps are given in the actual order here as
# a list, changing the order here does not change the order of execution, which is fixed.
steps:
  # Parse and insert table data
  - create_and_load_tables

  # Modify table metadata and field schemas
  - modify_metadata_and_schemas

  # Generate documentation files
  - generate_documentation

  # Run tests to confirm consistency in data across the various sources
  - validate_data