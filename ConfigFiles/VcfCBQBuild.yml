version: 1

files_and_buckets_and_tables:
  # Name of the staging project 
  STAGING_PROJECT:
  
  # Name of the staging dataset 
  STAGING_DATASET_ID: 
 
  # Name of the staging table 
  STAGING_TABLE_ID: 

  # Publish Project ID
  PUBLISH_PROJECT: 

  # Publish Dataset ID
  PUBLISH_DATASET_ID: 

  # Publish Table ID
  PUBLISH_TABLE_ID: 

  # File name to send all vcfs to a csv 
  PARSED_VARIANT_CALL_FILE :  

  # File name to send the parsed 'INFO' column 
  FORMAT_COLUMN_SPLIT_FILE: 

  # File name that stores the merged csv file (PARSED_VARIANT_CALL_FILE + FOMAT_COLUMN_SPLIT_FILE) 
  FINAL_MERGED_CSV: 

  DATAFRAME_INFO_FILE:

  # Proved  a bucket path to store FINAL_MERGED_CSV 
  BUCKET_PATH: 

  # Schema file that holds all the description for each column found in SchemaFiles directory (PROVIDE A PATH)
  SCHEMA_WITH_DESCRIPTION: 
  
  # This file will contain the format information of a Pandas Dataframe describing the schema of the FINAL_MERGED_CSV
  FORMAT_INFO_FILE:

  # Name of the Program Ex. TCGA
  PROGRAM_NAME: 

  # Releasse table for filedata_active (make sure to change ## to the release number)
  FILEDATA_ACTIVE: 

  # Relealse table for GDCID_TOGCSURL
  GDCID_TO_GCSURL: 

  # Release table for aliquot2caseid 
  ALIQUOT_TO_CASEID: 
  
  # Provide the path to the Labels, Descritptions, and FriendlyNames text file 
  LABEL_DESCRIPTION_FREINDLYNAME: 

  # Run 'True' only if LiftOver VCF files exist in the program 
  LEGACY_TAG: False  

  # Run 'True' only if it vcf files don't contain any Normal columns within each file
  NORMAL_COL: True
        
  # Set the number of cores to run in parallel
  MAX_WORKERS:



steps:
  - extract_metadata_table

  - transform_vcf  

  - create_new_columns

  - merge_csv_files

  - build_a_simple_schema

  - push_csv_to_bucket 

  - load_to_staging_environment

  - load_to_production_environment
